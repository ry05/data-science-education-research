{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0c236e00cb2504b8feadf115dc1fb937fdc1f15d4b269bc00694bd48dbccf7690",
   "display_name": "Python 3.8.10 64-bit ('capstone_project': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.findamasters.com/masters-degrees/msc-degrees/usa/full-time/?430l-3h0&Keywords=%22data%22%20or%20%22analytics%22%20or%20%22analysis%22%20or%20%22machine%20learning%22%20or%20%22ml%22%20or%20%22artificial%20intelligence%22%20or%20%22statistics%22'\n",
    "# obtained after searching with the relevant keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(response):\n",
    "\n",
    "    # make soup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # get data\n",
    "    programs = soup.find_all('div', class_ = 'course-content-info')\n",
    "    titles = [program.h3.text for program in programs]\n",
    "    institutes = [program.select('.instLink')[0].text for program in programs]\n",
    "    departments = [program.select('.deptLink')[0].text for program in programs]\n",
    "    labels = [program.select('.course-icon-area')[0].text for program in programs] \n",
    "    labels = [label.replace('\\xa0', '').replace('\\n', ',').strip(',') for label in labels]\n",
    "\n",
    "    return titles, institutes, departments, labels\n",
    "\n",
    "def make_data(base_url, low, high):\n",
    "\n",
    "    title = []\n",
    "    inst = []\n",
    "    dept = []\n",
    "    lab = []\n",
    "\n",
    "    for page_num in range(low, high+1):\n",
    "\n",
    "        time.sleep(5)\n",
    "        print(f'Extracting from page {page_num}')\n",
    "\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                base_url,\n",
    "                params = {'PG':page_num},\n",
    "                headers = {'User-agent': 'DSE Scraper'},\n",
    "                timeout=(5,5)\n",
    "            )\n",
    "        except:\n",
    "            print(f'Connection dropped. Page: {page_num}')\n",
    "            continue\n",
    "\n",
    "        t, i, d, l = extract_data(response)\n",
    "        title += t\n",
    "        inst += i\n",
    "        dept += d\n",
    "        lab += l\n",
    "\n",
    "        print(len(t))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            title = title,\n",
    "            institute = inst,\n",
    "            department = dept,\n",
    "            label = lab\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('Data extraction complete.')\n",
    "\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting from page 1\n",
      "15\n",
      "Extracting from page 2\n",
      "15\n",
      "Extracting from page 3\n",
      "15\n",
      "Extracting from page 4\n",
      "15\n",
      "Extracting from page 5\n",
      "15\n",
      "Extracting from page 6\n",
      "2\n",
      "Extracting from page 7\n",
      "0\n",
      "Extracting from page 8\n",
      "0\n",
      "Extracting from page 9\n",
      "0\n",
      "Data extraction complete.\n"
     ]
    }
   ],
   "source": [
    "temp_df = make_data(URL, 1, 9)"
   ]
  },
  {
   "source": [
    "Problems  \n",
    "1. From page 6, only 2 courses extracted  \n",
    "2. From page 7, none were extracted  \n",
    "3. From page 8, none were extracted  \n",
    "4. From page 9, none were extracted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(77, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['title'] = temp_df.title.apply(lambda x: x.replace('\\n', ' ').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('data/findamasters_usa_raw_jun1_2021.csv', index=False)"
   ]
  }
 ]
}